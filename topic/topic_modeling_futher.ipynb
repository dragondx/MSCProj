{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit"
  },
  "interpreter": {
   "hash": "1b174d106187cf4c36b481e4f9775d9b6103c84ebc5bd0573d3cc5e86d067305"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "speeches = pd.read_csv('./all_ECB_speeches.csv', delimiter='|', error_bad_lines=False)\n",
    "speeches.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date           speakers  \\\n",
       "0  2021-05-27    Isabel Schnabel   \n",
       "1  2021-05-27    Luis de Guindos   \n",
       "2  2021-05-25     Philip R. Lane   \n",
       "3  2021-05-19      Fabio Panetta   \n",
       "4  2021-05-06  Christine Lagarde   \n",
       "\n",
       "                                               title  \\\n",
       "0  Societal responsibility and central bank indep...   \n",
       "1           Climate change and financial integration   \n",
       "2                            The ECB strategy review   \n",
       "3  At the edge of tomorrow: preparing the future ...   \n",
       "4   Towards a green capital markets union for Europe   \n",
       "\n",
       "                                            subtitle  \\\n",
       "0  Keynote speech by Isabel Schnabel, Member of t...   \n",
       "1  Keynote speech by Luis de Guindos, Vice-Presid...   \n",
       "2  Presentation by Philip R. Lane, Member of the ...   \n",
       "3  Introductory remarks by Fabio Panetta, Member ...   \n",
       "4  Speech by Christine Lagarde, President of the ...   \n",
       "\n",
       "                                            contents  \n",
       "0     SPEECH  Societal responsibility and central...  \n",
       "1     SPEECH  Climate change and financial integr...  \n",
       "2                                                NaN  \n",
       "3     SPEECH  At the edge of tomorrow: preparing ...  \n",
       "4     SPEECH  Towards a green capital markets uni...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>speakers</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>Isabel Schnabel</td>\n",
       "      <td>Societal responsibility and central bank indep...</td>\n",
       "      <td>Keynote speech by Isabel Schnabel, Member of t...</td>\n",
       "      <td>SPEECH  Societal responsibility and central...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>Luis de Guindos</td>\n",
       "      <td>Climate change and financial integration</td>\n",
       "      <td>Keynote speech by Luis de Guindos, Vice-Presid...</td>\n",
       "      <td>SPEECH  Climate change and financial integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>Philip R. Lane</td>\n",
       "      <td>The ECB strategy review</td>\n",
       "      <td>Presentation by Philip R. Lane, Member of the ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>Fabio Panetta</td>\n",
       "      <td>At the edge of tomorrow: preparing the future ...</td>\n",
       "      <td>Introductory remarks by Fabio Panetta, Member ...</td>\n",
       "      <td>SPEECH  At the edge of tomorrow: preparing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>Towards a green capital markets union for Europe</td>\n",
       "      <td>Speech by Christine Lagarde, President of the ...</td>\n",
       "      <td>SPEECH  Towards a green capital markets uni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "speeches.iloc[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "date                                               2021-05-27\n",
       "speakers                                      Isabel Schnabel\n",
       "title       Societal responsibility and central bank indep...\n",
       "subtitle    Keynote speech by Isabel Schnabel, Member of t...\n",
       "contents       SPEECH  Societal responsibility and central...\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "speeches = speeches.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "speeches = speeches.loc[speeches.subtitle.str.contains(\"\\sPresident\\s\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "speeches['contents'] = speeches['contents'].replace('SPEECH', '', regex=True)\n",
    "speeches['contents'] = speeches['contents'].replace('\\((.*?)\\)', '', regex=True)\n",
    "speeches['contents'] = speeches['contents'].replace('\\[(.*?)\\]', '', regex=True)\n",
    "speeches['contents'] = speeches['contents'].replace('Note.*?\\.', '', regex=True)\n",
    "speeches['contents'] = speeches['contents'].replace('Chart .*?\\..*?\\.', '', regex=True)\n",
    "speeches['contents'] = speeches['contents'].replace('[,\\.!?]', '', regex=True)\n",
    "\n",
    "speeches['contents'] = speeches['contents'].replace('\\s[a-z]{1,2}\\s', '', regex=True)\n",
    "\n",
    "speeches['contents'] = speeches['contents'].replace('[^\\x00-\\x7F]+',' ', regex=True)\n",
    "\n",
    "speeches['contents'] = speeches['contents'].replace('[^\\w\\s]', '', regex=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS as stop_words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_non_english(texts):\n",
    "    return [[w for w in nltk.wordpunct_tokenize(\" \".join(doc)) if w.lower() in words or not w.isalpha()] for doc in texts]\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "def lemmatize(texts):\n",
    "    return [[lemmatizer.lemmatize(w) for w in doc] for doc in texts]\n",
    "\n",
    "def noun_only(texts):\n",
    "    return [[word[0] for word in nltk.pos_tag(doc) if word[1] in ['NN','JJ','JJR','JJS','NNP','NNS']] for doc in texts]\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\felix\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "s2004 = speeches.loc[speeches['date'].str.contains(\"2004\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "s2008 = speeches.loc[speeches['date'].str.contains(\"2008\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "s2012 = speeches.loc[speeches['date'].str.contains(\"2012\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "s2016 = speeches.loc[speeches['date'].str.contains(\"2016\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "s202021 = speeches.loc[speeches['date'].str.contains(\"2020|2021\"),:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "len(s2016)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis.sklearn \n",
    "import numpy as np\n",
    "\n",
    "num_topics = 5\n",
    "\n",
    "def preprocess(input_data):\n",
    "    data = input_data.contents.values.tolist()\n",
    "\n",
    "\n",
    "    # data = [input_data.iloc[1].contents]\n",
    "\n",
    "    data_words = list(sent_to_words(data))\n",
    "\n",
    "\n",
    "    data_words = remove_non_english(data_words)\n",
    "    \n",
    "    data_words = remove_stopwords(data_words)\n",
    "    data_words = lemmatize(data_words)\n",
    "\n",
    "    data_words = remove_stopwords(data_words)\n",
    "\n",
    "    data_words = noun_only(data_words)\n",
    "\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "    def make_bigrams(texts):\n",
    "        return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "    data_words = make_bigrams(data_words)\n",
    "\n",
    "    return data_words\n",
    "\n",
    "def gen_corpus(data_words):\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # id2word.filter_extremes( no_above=0.9, keep_n=100000)\n",
    "    # Create Corpus\n",
    "    texts = data_words\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "    return id2word, corpus, corpus_tfidf\n",
    "\n",
    "def lda_sklearn(data_words):\n",
    "\n",
    "    vect = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "    vect_tfidf = TfidfVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for doc in data_words:\n",
    "        docs.append(\" \".join(doc))\n",
    "\n",
    "    corpus_sklearn_bow = vect.fit_transform(docs)\n",
    "    corpus_sklearn_tfidf = vect_tfidf.fit_transform(docs)\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics)\n",
    "\n",
    "\n",
    "    lda_dtf=lda.fit_transform(corpus_sklearn_bow)\n",
    "\n",
    "    lda_tfidf = LatentDirichletAllocation(n_components=num_topics)\n",
    "\n",
    "\n",
    "    lda_dtf_tfidf=lda.fit_transform(corpus_sklearn_tfidf)\n",
    "\n",
    "    \n",
    "\n",
    "    # sorting=np.argsort(lda.components_)[:,::-1]\n",
    "\n",
    "    # features=np.array(vect.get_feature_names())\n",
    "\n",
    "    return vect, vect_tfidf, lda, lda_tfidf, corpus_sklearn_bow, corpus_sklearn_tfidf\n",
    "\n",
    "def run_lda(id2word, corpus, data_words, k=5,  a='symmetric', b=None):\n",
    "    \n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word, \n",
    "                                        workers=10, \n",
    "                                        num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "\n",
    "    coherence_model_lda = gensim.models.coherencemodel.CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    # Print the Keyword in the 10 topics\n",
    "    pprint(lda_model.print_topics())\n",
    "    print(coherence_model_lda.get_coherence())\n",
    "    doc_lda = lda_model[corpus]\n",
    "\n",
    "    return lda_model, coherence_model_lda.get_coherence()\n",
    "\n",
    "def lda_mallet(id2word, corpus):\n",
    "    mallet_path = 'mallet-2.0.8\\\\bin\\\\mallet'\n",
    "    ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "    pprint(lda_model.print_topics())\n",
    "    doc_lda = lda_model[corpus]\n",
    "    \n",
    "    return ldamallet\n",
    "\n",
    "def visualize(lda_model, corpus, id2word, mode, k=5):\n",
    "    # Visualize the topics\n",
    "    pyLDAvis.enable_notebook()\n",
    "    LDAvis_data_filepath = os.path.join('ldavis_'+ mode +'_'+str(k))\n",
    "\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "    # load the pre-prepared pyLDAvis data from disk\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "    pyLDAvis.save_html(LDAvis_prepared,'ldavis_'+ mode +'_'+ str(k) +'.html')\n",
    "    LDAvis_prepared\n",
    "\n",
    "\n",
    "def visualize_sklearn(lda_model, corpus, id2word, mode):\n",
    "    # Visualize the topics\n",
    "    pyLDAvis.enable_notebook()\n",
    "    LDAvis_data_filepath = os.path.join('ldavis_'+ mode +'_'+str(num_topics))\n",
    "\n",
    "    LDAvis_prepared = pyLDAvis.sklearn.prepare(lda_model, corpus, id2word,mds='mmds')\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "    # load the pre-prepared pyLDAvis data from disk\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "    pyLDAvis.save_html(LDAvis_prepared,'ldavis_'+ mode +'_'+ str(num_topics) +'.html')\n",
    "    LDAvis_prepared"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data_words = preprocess(s2016)\n",
    "id2word, corpus, corpus_tfidf = gen_corpus(data_words)\n",
    "lda_bow, cv_score = run_lda(id2word, corpus, data_words)\n",
    "lad_tfidf, cv_score = run_lda(id2word, corpus_tfidf, data_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "[(0,\n",
      "  '0.021*\"union\" + 0.013*\"trust\" + 0.009*\"stability\" + 0.007*\"monetary\" + '\n",
      "  '0.007*\"growth\" + 0.007*\"today\" + 0.006*\"way\" + 0.006*\"pact\" + '\n",
      "  '0.006*\"compliance\" + 0.006*\"convergence\"'),\n",
      " (1,\n",
      "  '0.034*\"area\" + 0.030*\"monetary\" + 0.023*\"policy\" + 0.022*\"economic\" + '\n",
      "  '0.017*\"market\" + 0.017*\"growth\" + 0.014*\"financial\" + 0.012*\"recovery\" + '\n",
      "  '0.011*\"economy\" + 0.010*\"structural\"'),\n",
      " (2,\n",
      "  '0.026*\"policy\" + 0.021*\"monetary\" + 0.015*\"income\" + 0.014*\"asset\" + '\n",
      "  '0.013*\"financial\" + 0.013*\"area\" + 0.012*\"net\" + 0.012*\"wealth\" + '\n",
      "  '0.011*\"real\" + 0.010*\"economy\"'),\n",
      " (3,\n",
      "  '0.001*\"policy\" + 0.001*\"area\" + 0.001*\"monetary\" + 0.001*\"financial\" + '\n",
      "  '0.001*\"global\" + 0.001*\"inflation\" + 0.001*\"economic\" + 0.001*\"market\" + '\n",
      "  '0.001*\"economy\" + 0.001*\"crisis\"'),\n",
      " (4,\n",
      "  '0.037*\"policy\" + 0.028*\"monetary\" + 0.026*\"area\" + 0.022*\"inflation\" + '\n",
      "  '0.014*\"low\" + 0.014*\"global\" + 0.014*\"economic\" + 0.013*\"financial\" + '\n",
      "  '0.013*\"economy\" + 0.013*\"growth\"')]\n",
      "0.3533365767155114\n",
      "[(0,\n",
      "  '0.002*\"data\" + 0.002*\"statistic\" + 0.001*\"republic\" + 0.001*\"eighth\" + '\n",
      "  '0.001*\"industry\" + 0.001*\"granular\" + 0.001*\"emu\" + 0.001*\"collection\" + '\n",
      "  '0.001*\"credible\" + 0.001*\"reform\"'),\n",
      " (1,\n",
      "  '0.002*\"research\" + 0.002*\"optimal\" + 0.002*\"arc\" + 0.001*\"distributional\" + '\n",
      "  '0.001*\"analysis\" + 0.001*\"theoretical\" + 0.001*\"ass\" + 0.001*\"groundwork\" + '\n",
      "  '0.001*\"conjunctural\" + 0.001*\"maximum\"'),\n",
      " (2,\n",
      "  '0.002*\"wealth\" + 0.002*\"confidence\" + 0.001*\"outlook\" + 0.001*\"recovery\" + '\n",
      "  '0.001*\"data\" + 0.001*\"unconventional\" + 0.001*\"nominal\" + 0.001*\"net\" + '\n",
      "  '0.001*\"distributional\" + 0.001*\"income\"'),\n",
      " (3,\n",
      "  '0.002*\"trust\" + 0.002*\"german\" + 0.001*\"compliance\" + 0.001*\"excess\" + '\n",
      "  '0.001*\"nominal\" + 0.001*\"reunification\" + 0.001*\"responsibility\" + '\n",
      "  '0.001*\"pact\" + 0.001*\"berlin\" + 0.001*\"discipline\"'),\n",
      " (4,\n",
      "  '0.003*\"labour\" + 0.002*\"inflation\" + 0.002*\"recovery\" + 0.002*\"eu\" + '\n",
      "  '0.002*\"parliament\" + 0.002*\"central\" + 0.002*\"systemic\" + 0.002*\"domestic\" '\n",
      "  '+ 0.002*\"bond\" + 0.002*\"paper\"')]\n",
      "0.42974588183358514\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "visualize(lda_bow, corpus, id2word, \"bow\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\n",
    "visualize(lad_tfidf, corpus, id2word, \"tfidf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data_words = preprocess(s2016)\n",
    "vect, vect_tfidf, lda, lda_tfidf, corpus_sklearn_bow, corpus_sklearn_tfidf = lda_sklearn(data_words)\n",
    "visualize_sklearn(lda, corpus_sklearn_bow, vect, \"bow\")\n",
    "# visualize_sklearn(lda_tfidf, corpus_sklearn_tfidf, vect_tfidf, \"tfidf\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data_words = preprocess(speeches)\n",
    "id2word, corpus, corpus_tfidf = gen_corpus(data_words)\n",
    "# lda_bow, cv_score = run_lda(id2word, corpus, data_words)\n",
    "# lad_tfidf, cv_score = run_lda(id2word, corpus_tfidf, data_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# # grid search\n",
    "\n",
    "# import numpy as np\n",
    "# import tqdm\n",
    "\n",
    "\n",
    "# grid = {}\n",
    "# grid['Validation_Set'] = {}\n",
    "\n",
    "# # Topics range\n",
    "# min_topics = 2\n",
    "# max_topics = 11\n",
    "# step_size = 1\n",
    "# topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# # Alpha parameter\n",
    "# alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# # Beta parameter\n",
    "# beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta.append('symmetric')\n",
    "\n",
    "# # Validation sets\n",
    "# num_of_docs = len(corpus)\n",
    "# corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "#                # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "#                gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "#                corpus]\n",
    "# corpus_title = ['75% Corpus', '100% Corpus']\n",
    "# model_results = {'Validation_Set': [],\n",
    "#                  'Topics': [],\n",
    "#                  'Alpha': [],\n",
    "#                  'Beta': [],\n",
    "#                  'Coherence': []\n",
    "#                 }\n",
    "\n",
    "# # Can take a long time to run\n",
    "# if 1 == 1:\n",
    "#     pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "#     # iterate through validation corpuses\n",
    "#     for i in range(len(corpus_sets)):\n",
    "#         # iterate through number of topics\n",
    "#         for k in topics_range:\n",
    "#             # iterate through alpha values\n",
    "#             for a in alpha:\n",
    "#                 # iterare through beta values\n",
    "#                 for b in beta:\n",
    "#                     # get the coherence score for the given parameters\n",
    "#                     model, cv = run_lda(id2word, corpus_tfidf, data_words, k=k, a=a, b=b)\n",
    "#                     # compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "#                                                 #   k=k, a=a, b=b)\n",
    "#                     # Save the model results\n",
    "#                     model_results['Validation_Set'].append(corpus_title[i])\n",
    "#                     model_results['Topics'].append(k)\n",
    "#                     model_results['Alpha'].append(a)\n",
    "#                     model_results['Beta'].append(b)\n",
    "#                     model_results['Coherence'].append(cv)\n",
    "                    \n",
    "#                     pbar.update(1)\n",
    "#     pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "#     pbar.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# per quarter\n",
    "\n",
    "quarters = [\"(1|2|3)\",\"(4|5|6)\", \"(7|8|9)\",\"(10|11|12)\"]\n",
    "\n",
    "for year in range(1997,2022):\n",
    "    for index, quarter in enumerate(quarters):\n",
    "        data = speeches.loc[speeches['date'].str.contains(str(year) + '-0?' + quarter),:]\n",
    "        \n",
    "        print(year, \" \", quarter, \"(\"+str(len(data))+\" docs)\",\": \")\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        data_words = preprocess(data)\n",
    "        id2word, corpus, corpus_tfidf = gen_corpus(data_words)\n",
    "        lda_bow, cv = run_lda(id2word, corpus, data_words)  \n",
    "        lad_tfidf, cv_tfidf = run_lda(id2word, corpus_tfidf, data_words)\n",
    "        visualize(lda_bow, corpus, id2word, \"bow_\"+str(year)+\"_\"+str(index+1))\n",
    "        visualize(lad_tfidf, corpus, id2word, \"tfidf_\"+str(year)+\"_\"+str(index+1))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1997   (1|2|3) (9 docs) : \n",
      "[(0,\n",
      "  '0.001*\"policy\" + 0.001*\"stability\" + 0.001*\"monetary\" + 0.001*\"price\" + '\n",
      "  '0.001*\"inflation\" + 0.001*\"economic\" + 0.001*\"central\" + 0.001*\"rate\" + '\n",
      "  '0.001*\"exchange\" + 0.001*\"area\"'),\n",
      " (1,\n",
      "  '0.057*\"monetary\" + 0.045*\"policy\" + 0.029*\"price\" + 0.027*\"inflation\" + '\n",
      "  '0.026*\"stability\" + 0.024*\"central\" + 0.014*\"rate\" + 0.012*\"growth\" + '\n",
      "  '0.011*\"exchange\" + 0.011*\"strategy\"'),\n",
      " (2,\n",
      "  '0.032*\"monetary\" + 0.029*\"policy\" + 0.024*\"stability\" + 0.022*\"price\" + '\n",
      "  '0.022*\"inflation\" + 0.019*\"growth\" + 0.015*\"economic\" + 0.013*\"banking\" + '\n",
      "  '0.013*\"financial\" + 0.011*\"central\"'),\n",
      " (3,\n",
      "  '0.036*\"exchange\" + 0.035*\"area\" + 0.034*\"rate\" + 0.025*\"monetary\" + '\n",
      "  '0.025*\"policy\" + 0.022*\"stability\" + 0.020*\"convergence\" + 0.019*\"central\" '\n",
      "  '+ 0.016*\"economic\" + 0.012*\"union\"'),\n",
      " (4,\n",
      "  '0.001*\"monetary\" + 0.001*\"stability\" + 0.001*\"policy\" + 0.001*\"rate\" + '\n",
      "  '0.001*\"central\" + 0.001*\"exchange\" + 0.001*\"inflation\" + 0.001*\"price\" + '\n",
      "  '0.001*\"financial\" + 0.001*\"area\"')]\n",
      "0.3234794945409457\n",
      "[(0,\n",
      "  '0.002*\"objective\" + 0.002*\"intermediate\" + 0.002*\"job\" + 0.002*\"strategy\" + '\n",
      "  '0.002*\"variable\" + 0.002*\"effectiveness\" + 0.002*\"indicator\" + '\n",
      "  '0.002*\"target\" + 0.002*\"inflation\" + 0.002*\"theoretical\"'),\n",
      " (1,\n",
      "  '0.003*\"emu\" + 0.002*\"competition\" + 0.002*\"labour\" + 0.002*\"unanticipated\" '\n",
      "  '+ 0.002*\"relative\" + 0.002*\"exchange\" + 0.002*\"efficiency\" + 0.002*\"income\" '\n",
      "  '+ 0.002*\"investment\" + 0.002*\"reliable\"'),\n",
      " (2,\n",
      "  '0.003*\"japan\" + 0.002*\"objective\" + 0.002*\"intermediate\" + 0.002*\"strategy\" '\n",
      "  '+ 0.002*\"variable\" + 0.002*\"indicator\" + 0.002*\"mean\" + '\n",
      "  '0.002*\"effectiveness\" + 0.002*\"target\" + 0.002*\"inflation\"'),\n",
      " (3,\n",
      "  '0.003*\"convergence\" + 0.003*\"exchange\" + 0.003*\"banking\" + '\n",
      "  '0.003*\"asymmetric\" + 0.002*\"necessary\" + 0.002*\"fluctuation\" + '\n",
      "  '0.002*\"western\" + 0.002*\"present\" + 0.002*\"agreement\" + 0.002*\"technical\"'),\n",
      " (4,\n",
      "  '0.003*\"higher\" + 0.002*\"convergence\" + 0.002*\"emu\" + 0.002*\"persistent\" + '\n",
      "  '0.002*\"consensus\" + 0.002*\"action\" + 0.002*\"exchange\" + 0.002*\"low\" + '\n",
      "  '0.002*\"infrastructure\" + 0.002*\"early\"')]\n",
      "0.3522092500848907\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'num_topics'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1597a0d0f04e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mlda_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_lda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mlad_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_lda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"bow_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlad_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tfidf_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-382f86f06c3e>\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(lda_model, corpus, id2word, mode, k)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mLDAvis_data_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ldavis_'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[0mLDAvis_prepared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLDAvis_data_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLDAvis_prepared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyLDAvis\\gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mopts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyLDAvis\\gensim_models.py\u001b[0m in \u001b[0;36m_extract_data\u001b[1;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mnum_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlda_alpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mnum_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'num_topics'"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# per quarter\n",
    "\n",
    "quarters = [\"(1|2|3)\",\"(4|5|6)\", \"(7|8|9)\",\"(10|11|12)\"]\n",
    "\n",
    "for year in range(1997,2022):\n",
    "    for index, quarter in enumerate(quarters):\n",
    "        data = speeches.loc[speeches['date'].str.contains(str(year) + '-0?' + quarter),:]\n",
    "        \n",
    "        print(year, \" \", quarter, \"(\"+str(len(data))+\" docs)\",\": \")\n",
    "        if len(data) == 0:\n",
    "            continue\n",
    "        data_words = preprocess(data)\n",
    "        vect, vect_tfidf, lda, lda_tfidf, corpus_sklearn_bow, corpus_sklearn_tfidf = lda_sklearn(data_words)\n",
    "        visualize_sklearn(lda, corpus_sklearn_bow, vect, \"bow_sklearn_\"+str(year)+\"_\"+str(index+1))\n",
    "       \n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1997   (1|2|3) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1997   (4|5|6) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1997   (7|8|9) (1 docs) : \n",
      "1997   (10|11|12) (7 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1998   (1|2|3) (16 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1998   (4|5|6) (1 docs) : \n",
      "1998   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1998   (10|11|12) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1999   (1|2|3) (20 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1999   (4|5|6) (7 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1999   (7|8|9) (4 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "1999   (10|11|12) (12 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2000   (1|2|3) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2000   (4|5|6) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2000   (7|8|9) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2000   (10|11|12) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2001   (1|2|3) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2001   (4|5|6) (7 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2001   (7|8|9) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2001   (10|11|12) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2002   (1|2|3) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2002   (4|5|6) (7 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2002   (7|8|9) (4 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2002   (10|11|12) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2003   (1|2|3) (12 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2003   (4|5|6) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2003   (7|8|9) (3 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2003   (10|11|12) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2004   (1|2|3) (24 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2004   (4|5|6) (17 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2004   (7|8|9) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2004   (10|11|12) (15 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2005   (1|2|3) (17 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2005   (4|5|6) (13 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2005   (7|8|9) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2005   (10|11|12) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2006   (1|2|3) (21 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2006   (4|5|6) (14 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2006   (7|8|9) (1 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2006   (10|11|12) (14 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2007   (1|2|3) (19 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2007   (4|5|6) (20 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2007   (7|8|9) (15 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2007   (10|11|12) (14 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2008   (1|2|3) (31 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2008   (4|5|6) (16 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2008   (7|8|9) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2008   (10|11|12) (14 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2009   (1|2|3) (27 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2009   (4|5|6) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2009   (7|8|9) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2009   (10|11|12) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2010   (1|2|3) (21 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2010   (4|5|6) (20 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2010   (7|8|9) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2010   (10|11|12) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2011   (1|2|3) (17 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2011   (4|5|6) (16 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2011   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2011   (10|11|12) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2012   (1|2|3) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2012   (4|5|6) (7 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2012   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2012   (10|11|12) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2013   (1|2|3) (16 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2013   (4|5|6) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2013   (7|8|9) (4 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2013   (10|11|12) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2014   (1|2|3) (14 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2014   (4|5|6) (3 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2014   (7|8|9) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2014   (10|11|12) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2015   (1|2|3) (19 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2015   (4|5|6) (4 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2015   (7|8|9) (2 docs) : \n",
      "2015   (10|11|12) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2016   (1|2|3) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2016   (4|5|6) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2016   (7|8|9) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2016   (10|11|12) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2017   (1|2|3) (10 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2017   (4|5|6) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2017   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2017   (10|11|12) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2018   (1|2|3) (9 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2018   (4|5|6) (4 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2018   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2018   (10|11|12) (6 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2019   (1|2|3) (13 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2019   (4|5|6) (3 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2019   (7|8|9) (2 docs) : \n",
      "2019   (10|11|12) (8 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2020   (1|2|3) (11 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2020   (4|5|6) (4 docs) : \n",
      "2020C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "   (7|8|9) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2020   (10|11|12) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2021   (1|2|3) (5 docs) : \n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "C:\\Users\\felix\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n",
      "2021   (4|5|6) (2 docs) : \n",
      "2021   (7|8|9) (0 docs) : \n",
      "2021   (10|11|12) (0 docs) : \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# deeper data analytics\n",
    "\n",
    "\n",
    "# dataset generally a bit short\n",
    "\n",
    "# 3 docs inconclusive -> a bit too short to work\n",
    "# tried tfidf / bag of words approach \n",
    "# did tuning according to paper, cleaned text, stop words, lemmatize, and stemming.\n",
    "#     extreme cleaninng of text ( remove sources, charts description, to give more coherent)\n",
    "# remove extreme popular terms (did not work as well)\n",
    "# ran over all the dataset and tracking changes on topics on quarterly basis from year 1997\n",
    "\n",
    "\n",
    "# some word clouds for exploratory sentiment analysis (also applied similar pre-processing techniques)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python38\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-d22fc322a253>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-d22fc322a253>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    deeper data analytics\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}