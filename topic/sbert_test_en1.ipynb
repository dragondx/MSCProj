{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, util\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import numpy as np\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def kl_divergence(p,q):\r\n",
    "    return np.sum(p * (np.log2(p)-np.log2(q)))\r\n",
    "\r\n",
    "def js_divergence(p,q):\r\n",
    "    m = 0.5 * (p + q)\r\n",
    "    return 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\r\n",
    "\r\n",
    "def one_hot(p,q):\r\n",
    "    return 1 if p==q else 0\r\n",
    "\r\n",
    "def sigmoid(val):\r\n",
    "    return 1/(1+np.exp(-17*(val-0.5)))\r\n",
    "\r\n",
    "# js ensure symmetric\r\n",
    "def similarity(p,q,mode=\"js\"):\r\n",
    "    if mode == \"js\":\r\n",
    "        return sigmoid(np.exp2(-js_divergence(np.array(p),np.array(q))))\r\n",
    "    elif mode == \"kl\":\r\n",
    "        return sigmoid(np.exp2(-kl_divergence(np.array(p),np.array(q))))\r\n",
    "    elif mode == \"one-hot\":\r\n",
    "        return one_hot(p,q)\r\n",
    "\r\n",
    "def get_random_index_pairs(num_data, amount):\r\n",
    "    return np.random.randint(num_data, size=(amount, 2))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# flatten to one list for all 3\r\n",
    "with open('train_data.pickle', 'rb') as file:\r\n",
    "    train = pickle.load(file)\r\n",
    "\r\n",
    "with open('gpt.pickle', 'rb') as file:\r\n",
    "    gpt = pickle.load(file)\r\n",
    "    \r\n",
    "with open('gpt.pickle', 'rb') as file:\r\n",
    "    gpt2 = pickle.load(file)\r\n",
    "\r\n",
    "gpt = [item for sublist in gpt for item in sublist]\r\n",
    "gpt2 = [item for sublist in gpt2 for item in sublist]\r\n",
    "\r\n",
    "mixed = gpt[200:] + train + gpt2[200:]\r\n",
    "test = gpt2[:200] + gpt[:200]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = SentenceTransformer('./')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "with open('evaluation.pickle', 'rb') as file:\r\n",
    "    eval_dict = pickle.load(file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "classes = [\"banking\",\"valuation\",\"household\",\"real estate\",\"corporate\",\"external\",\"sovereign\",\"technology\", \"climate\", \"energy\", \"health\", \"eu\"]\r\n",
    "#cosine similarity\r\n",
    "#Compute embedding for both lists\r\n",
    "embedded_class_dictionary = {label: [] for label in classes}\r\n",
    "\r\n",
    "\r\n",
    "for label in classes:\r\n",
    "    for sentence in eval_dict[label]:\r\n",
    "        embeddings = model.encode(sentence, convert_to_tensor=True)\r\n",
    "        embedded_class_dictionary[label].append(embeddings)\r\n",
    "\r\n",
    "  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "import random\r\n",
    "import torch\r\n",
    "import math\r\n",
    "\r\n",
    "def rescale(dist):\r\n",
    "    beta = torch.mean(dist[math.ceil(0.25*len(dist)):math.floor(0.75*len(dist))])\r\n",
    "    alpha = torch.max(torch.tensor([(10+1/(torch.std(dist)/torch.mean(dist))), 400]))\r\n",
    "    return 1/(1+torch.exp(-alpha*(dist-beta)))\r\n",
    "\r\n",
    "def query(text, examples=10):\r\n",
    "    scores = []\r\n",
    "    text_vector = model.encode(text, convert_to_tensor=True)\r\n",
    "    for label in classes:\r\n",
    "        if label != \"eu\":\r\n",
    "            examples_list = random.sample(embedded_class_dictionary[label], k=examples)\r\n",
    "        else:\r\n",
    "            examples_list = embedded_class_dictionary[label]\r\n",
    "        cosine_scores = torch.tensor([util.pytorch_cos_sim(text_vector,  example) for example in examples_list])\r\n",
    "        scores.append(torch.mean(cosine_scores))\r\n",
    "    # torch.nn.functional.softmax(torch.tensor(scores))\r\n",
    "    scores = torch.tensor(scores)\r\n",
    "    scores = scores/torch.sum(scores)\r\n",
    "    scores = rescale(scores)\r\n",
    "    scores = scores/torch.sum(scores)\r\n",
    "    #softmax\r\n",
    "    return {label:score for label, score in zip(classes,scores)}, np.array(scores)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "\r\n",
    "query(\"In contrast to the radical forces buffeting valuations, for most companies, 2020 was a year of “strategy lockdown.\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'banking': tensor(0.0143),\n",
       "  'valuation': tensor(0.3063),\n",
       "  'household': tensor(0.0026),\n",
       "  'real estate': tensor(0.0196),\n",
       "  'corporate': tensor(0.5824),\n",
       "  'external': tensor(0.0066),\n",
       "  'sovereign': tensor(0.0155),\n",
       "  'technology': tensor(0.0163),\n",
       "  'climate': tensor(0.0082),\n",
       "  'energy': tensor(0.0059),\n",
       "  'health': tensor(0.0215),\n",
       "  'eu': tensor(0.0009)},\n",
       " array([0.01432589, 0.30633795, 0.00255404, 0.0195682 , 0.5823974 ,\n",
       "        0.00656773, 0.01546279, 0.0163366 , 0.00815779, 0.00585703,\n",
       "        0.02152549, 0.00090902], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "\r\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,top_k_accuracy_score\r\n",
    "def compute_metrics(labels, preds):\r\n",
    "    best = np.argmax(preds, axis=1)\r\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, best, average='macro')\r\n",
    "    acc = accuracy_score(labels, best)\r\n",
    "    top3 = top_k_accuracy_score(labels, preds ,k=3)\r\n",
    "    top2 = top_k_accuracy_score(labels, preds ,k=2)\r\n",
    "    return {\r\n",
    "        'accuracy': acc,\r\n",
    "        'f1': f1,\r\n",
    "        'precision': precision,\r\n",
    "        'recall': recall,\r\n",
    "        'top3': top3,\r\n",
    "        'top2': top2\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from tqdm import tqdm\r\n",
    "labels = []\r\n",
    "preds = []\r\n",
    "\r\n",
    "for item in tqdm(test):\r\n",
    "    labels.append(np.argmax(np.array(item[\"dist\"])))\r\n",
    "    preds.append(query(item[\"text\"])[1])\r\n",
    "preds = np.array(preds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 400/400 [00:45<00:00,  8.72it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "assert len(labels) == len(preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "compute_metrics(labels,preds)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'accuracy': 0.92,\n",
       " 'f1': 0.8316229467944879,\n",
       " 'precision': 0.8142551892551894,\n",
       " 'recall': 0.8727039627039627,\n",
       " 'top3': 0.975,\n",
       " 'top2': 0.965}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "6b31b91393804ba8dc9c9bfc0276b237c748fbfc9d237f295d2f8dc3a0ae1c04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}